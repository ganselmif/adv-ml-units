{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 bis: **Invariance** in a *shallow FCN* under data augmentation\n",
    "\n",
    "Advanced Topics in Machine Learning -- Spring 2023, UniTS\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/ganselmif/adv-ml-units/blob/main/notebooks/AdvML_UniTS_2023_Lab_04bis_FCN_Invariance.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High-level overview\n",
    "\n",
    "In this *Lab*, we will understand how the effect of *data augmentation* (whose effect on learned **weights** has been analyzed in the previous lab) translates to the **representation** learned by the model.\n",
    "\n",
    "Specifically, we define *representation* the (ordered) set of activations of a *neural network* model, which is dependent on the input, and can be seen as the way the model *sees* the data as a result of the learning process.\n",
    "\n",
    "To accomplish this goal, we will:\n",
    "\n",
    "- Load the weights resulting from the training of the model described in the previous lab;\n",
    "- Learn how to extract the activations of a given layer of the model, in response to a given input;\n",
    "- Evaluate such activations on mutually-rotated versions of the same input, and compare such activations to assess their *invariance*  with respect to the transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminary: adapt and re-run the previous notebook\n",
    "\n",
    "Before starting to delve into this lab, you should:\n",
    "- Go back to the previous *Lab* notebook;\n",
    "- Add the (single line of) code required to save the model weights after training;\n",
    "- Re-run the notebook, to make sure that the weights are saved correctly;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Re-)definition of the model\n",
    "\n",
    "Define the exact same model you used in the previous lab, and instantiate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights loading\n",
    "\n",
    "Load into the instance of your model the weights you just saved from the adapted notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "\n",
    "To test for a given transformation invariance, you should have pairs of (test) data obtained from the same image: one original, and one transformed.\n",
    "\n",
    "**Hint**: if you want to offload the task to already implemented `torchvision.transforms`, notice (to your advantage) that -- since we are just testing the model -- the dataset needs not to be in shuffled order!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation extraction\n",
    "\n",
    "Write a function that extracts the activations of a given layer of the model, in response to a given input. Try to remain as generic as possible, since you may need to re-use it in the future.\n",
    "\n",
    "**Hint**: Look up in the documentation the purpose and features of `hook`s. If you are in trouble, just ask!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invariance evaluation\n",
    "\n",
    "Recall the definition of *invariance* of (the result of) function $f$ with respect to transformation $g(\\cdot\\;; \\alpha)$ parametrized by $\\alpha$:\n",
    "\n",
    "$$f(g(x; \\alpha))=f(x)\\;\\;\\;\\; \\forall\\alpha$$\n",
    "\n",
    "With the function and data just defined, compare in a statistically-significant manner the activations of the model on the original and transformed versions of the same image. Comment on the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPkibvpTEMRILBn2/x8IuJj",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
